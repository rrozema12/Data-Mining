### Hw4.py

import naive_bayes as bayes
import table_utils
import file_system
import homework_util as homework
import constants
import partition
import output_util as output
import classifier_util
import hw4_util
import knn
import util


def _printExamples(table):
    """ Prints 5 example instances """
    test, training = partition.cut(table, 5)
    for instance in test:
        output.printInstance(instance)  # Print original instance

        # Calculate the actual and bayes predicted
        actual = instance[constants.INDICES['mpg']]

        # change the instance to the values we are testing from
        instance = homework.getNamedTuples(instance, 'cylinders', 'weight', 'year')
        predicted, probability = bayes.predict_label(training, instance, constants.INDICES['mpg'])

        output.printClassActual(actual, predicted)  # Print results


def _printAccuracy(table):
    """ Compares subsample accuracy with crossfolding accuracy
    Returns the labels for crossfolding because ...
    """
    output.printHeader('Predicitive Accuracy Naive Bayes')
    accuracy = classifier_util.accuracy(hw4_util.random_subsample_naive_bayes(table, 10))

    print('\tRandom Subsample')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    labels = hw4_util.stratified_cross_fold_naive_bayes(table, 10)
    accuracy = classifier_util.accuracy(labels)

    print('\tStratified CrossFolding')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    return labels


def _printConfusionMatrix(labels, name):
    """ Prints a confusion matrix for given labels """
    output.printHeader('Confusion Matrix')
    hw4_util.print_confusion_matrix(labels, name)


def step_one(table):
    """ Performs step one of homework 4 """
    output.printHeader("STEP 1: MPG Classified by Naive Bayes for Categorial")

    weight_index = constants.INDICES['weight']
    table = table_utils.mapCol(table, weight_index, homework.getNHTSASize)

    # Part 1 - Print 5 examples
    _printExamples(table)

    # Part 2 - Print Accuracy comparisons
    labels = _printAccuracy(table)

    # Part 3 - Print confusion matrix
    _printConfusionMatrix(labels, 'MPG')


def step_two(table):
    """ Performs step two of homework 4 """
    output.printHeader("STEP 2: Leave 'weight' as a continous attribute")

    # Part 1 - Print examples
    test, training = partition.cut(table, 5)
    for instance in test:
        output.printInstance(instance)  # Print original instance

        # Calculate the actual and bayes predicted
        actual = instance[constants.INDICES['mpg']]

        # change the instance to the values we are testing from
        instance = homework.getNamedTuples(instance, 'cylinders', 'weight', 'year')
        predicted, probability = bayes.predict_label(training,
            instance, constants.INDICES['mpg'], [constants.INDICES['weight']])

        output.printClassActual(actual, predicted)  # Print results

    # Part 2
    output.printHeader('Predicitive Accuracy Naive Bayes')
    accuracy = classifier_util.accuracy(
        hw4_util.random_subsample_naive_bayes(table, 10, [constants.INDICES['weight']]))

    print('\tRandom Subsample')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    labels = hw4_util.stratified_cross_fold_naive_bayes(table, 10, [constants.INDICES['weight']])
    accuracy = classifier_util.accuracy(labels)

    print('\tStratified CrossFolding')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    _printConfusionMatrix(labels, 'MPG')


def step_three(table):
    """ Analyzes the table based on Knn and Naive Bayes

    :param table: the table of the titanic dataset
    :return: nothing
    """
    output.printHeader("STEP 3: Titanic, Knn vs Naive Bayes")
    table = table_utils.mapCol(table, constants.INDICES['class'],
                               homework.get_class_value)
    table = table_utils.mapCol(table, constants.INDICES['age'],
                               homework.get_age_value)
    table = table_utils.mapCol(table, constants.INDICES['sex'],
                               homework.get_sex_value)
    table = table_utils.mapCol(table, constants.INDICES['survived'],
                               homework.get_survived_value)
    table = knn.normalize_table(table, [1,2,3])

    # KNN
    print('K_NN')

    labels = hw4_util.random_subsample_knn(table, 5, 10, constants.INDICES['survived'])
    accuracy = classifier_util.accuracy(labels)
    print('\tRandom Subsample (5)')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    labels = hw4_util.stratified_cross_fold_knn(table, 5, 10, constants.INDICES['survived'])
    accuracy = classifier_util.accuracy(labels)
    print('\tStratified Cross Folds (5)')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    # Naive Bayes
    print('\nNaive Bayes')

    accuracy = classifier_util.accuracy(
        hw4_util.random_subsample_naive_bayes(table, 10, [constants.INDICES['survived']]))

    print('\tRandom Subsample')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    labels = hw4_util.stratified_cross_fold_naive_bayes(table, 10, [constants.INDICES['survived']])
    accuracy = classifier_util.accuracy(labels)

    print('\tStratified CrossFolding')
    print('\t\tAccuracy = ' + str(accuracy) + ', error rate = ' + str(1 - accuracy))

    # Needs confusion matrix


def main():
    table = file_system.loadTable('auto-data-removedNA.csv')

    # Convert the weights in the table to their NHTSA discretization
    mpg_index = constants.INDICES['mpg']
    table = table_utils.mapCol(table, mpg_index, homework.getDeptEnergyRating)

    step_one(table)

    table = file_system.loadTable('auto-data-removedNA.csv')
    table = table_utils.mapCol(table, mpg_index, homework.getDeptEnergyRating)

    step_two(table)

    table = file_system.loadTable('titanic.txt')
    step_three(table)


if __name__ == "__main__":
    main()



### hw4_util.py
from tabulate import tabulate
import homework_util as homework
import constants
import naive_bayes as bayes
import util
import table_utils
import partition
import knn

def random_subsample_naive_bayes(table, k, contIndices=[]):
    """ Uses Naive Bayes and Random Subsampling to find labels """
    return _random_subsample(table, k, predict_labels, contIndices)


def random_subsample_knn(table, num_holdout, k, class_index):
    """ Uses knn and random subsampling to predict labels

    :param table: a table of data
    :param num_holdout: the number of random subsamples to run
    :param k: the number of nearest nieghbors
    :param class_index: the index where the class label is
    :return: eturns a list of tuples of the labels in the form [(actual, predicted),...]
    """
    labels = []

    # repeats the subsampling k times
    for i in range(num_holdout):
        test_set, training_set = partition.holdout(table)

        # gets the lables
        labels.extend(knn.knn(training_set, test_set, k, class_index))
    return labels

def stratified_cross_fold_knn(table, num_folds, k, class_index):
    """ Uses knn and stratified cross folding to predict labels

    :param table: a table of data
    :param num_folds: the number of folds to calculate
    :param k: the number of nearest nieghbors
    :param class_index: the index where the class label is
    :return: returns a list of tuples of the labels in the form [(actual, predicted),...]
    """
    labels = []
    folds = strat_folds(table, class_index, num_folds)
    for index in range(len(folds)):
        test = folds[index]  # creates the test from one fold
        training = []

        # meshes the rest of the folds together to make the training set
        for training_index in range(len(folds)):
            if training_index != index:
                training.extend(folds[training_index])

        labels.extend(knn.knn(training, test, k, class_index))
    return labels

def _random_subsample(table, k, classify, contIndices=[]):
    """
    Uses random subsampling to test labels on classify
    :param table: Table of data
    :param k: Number of times to run holdout method
    :return: labels in format list of tuples [(actual, predicted),...]
    """
    labels = []

    # repeats the subsampling k times
    for i in range(k):
        test_set, training_set = partition.holdout(table)

        # gets the lables
        labels.extend(classify(training_set, test_set, contIndices))
    return labels


def predict_labels(training, test, contIndices=[]):
    """ Using Naive Bayes it will predict values in test by using training

    :param training: A table of data
    :param test: A table of data in the same format as training
    :return: labels in format list of tuples [(actual, predicted),...]
    """
    labels = []
    for instance in test:
        actual = instance[constants.INDICES['mpg']]  # the actual label of the instance

        # change the instance to the values we are testing from
        instance = homework.getNamedTuples(instance, 'cylinders', 'weight', 'year')

        # gets the predicted label
        predicted, probability = bayes.predict_label(training,
            instance, constants.INDICES['mpg'], contIndices)

        # records the two labels
        labels.append((actual, predicted))
    return labels


def stratified_cross_fold_naive_bayes(table, k, contIndices=[]):
    """ Runs naive bayes on k stratified cross folds """
    return _stratified_cross_fold(table, k, predict_labels, contIndices)


def _stratified_cross_fold(table, k, classify, contIndices=[]):
    """
    Uses stratified crossfolding to create the training and test sets
    :param table: Table of data
    :param k: Number of folds
    :return: labels in format list of tuples [(actual, predicted),...]
    """
    labels = []
    folds = strat_folds(table, constants.INDICES['mpg'], k)
    for index in range(len(folds)):
        test = folds[index]  # creates the test from one fold
        training = []

        # meshes the rest of the folds together to make the training set
        for training_index in range(len(folds)):
            if training_index != index:
                training.extend(folds[training_index])

        labels.extend(classify(training, test, contIndices))
    return labels


def strat_folds(table, by_label_index, k):
    """
    Creates fold where each fold has the same distrubution of class labels as the origonal table

    :param table: table of data
    :param by_label_index: the class label index
    :param k: the number of partitions to create
    :return: a list of tables where each table is a folds, i.e.: [[P1],[P2],..., [Pnum]] where each P is a table
    """
    labels_to_rows = {}

    # spreads the data out into a dictionary where the key is the class label and the data is a table consisting of
    # rows with that class label {class_label:rows_with_class_label
    for row in table:
        label = row[by_label_index]
        try:
            labels_to_rows[label].append(row)
        except KeyError:
            labels_to_rows[label] = [row]

    # creates folds by evenly distributing the rows of each class label to the number of partitions
    folds = {}
    index = 0
    for key, table in labels_to_rows.iteritems():
        for row in table:
            try:
                folds[index].append(row)
            except KeyError:
                folds[index] = [row]
            index += 1
            if index > k:
                index = 0
    return util.dictionaryToArray(folds)


def print_confusion_matrix(labels, class_label_name):
    """ Prints the confusion matrix of the given labels

    :param labels: A list of tuples of class labels [(actual, predicted),...]
    :param class_label_name: The name of the class label
    """
    class_labels = list(set(table_utils.getCol(labels, 0)))  # all the actual class labels
    the_headers = [class_label_name]
    the_headers.extend(class_labels)
    the_headers.extend(['Total', 'Recognition (%)'])

    # makes an table filled with zeros of #columns = len(the_headers) and #rows = len(class_labels)
    confusion_matrix = [[0] * len(the_headers) for i in range(len(class_labels))]

    # fills out the confusion matrix with the predicted vs. actual
    for a_label_point in labels:
        actual, predicted = a_label_point
        confusion_matrix[class_labels.index(actual)][the_headers.index(predicted)] += 1

    # add the rest of the values to the confusion matrix
    for i in range(len(confusion_matrix)):
        row = confusion_matrix[i]  # current row

        # adding total to the confusion matrix
        total = sum(row)
        row[the_headers.index('Total')] = total  # add the total in for the row

        row[0]= class_labels[i]  # adds the class label for the row to the beginning of row

        # adding recognition to the confusion matrix (% of guesses in row that are correct
        recognition = row[the_headers.index(class_labels[i])] # TP
        recognition /= float(total)
        recognition *= 100
        row[the_headers.index('Recognition (%)')] = recognition

    # prints the table
    print tabulate(confusion_matrix, headers = the_headers, tablefmt="rst")


### math_utils.py

import util
import numpy
import math
import operator
from functools import partial

def slope(points, x_bar, y_bar):
    top_values = []
    bot_values = []
    for point in points:
        x = point[0]
        y = point[1]
        top_values.append((x - x_bar)*(y - y_bar))
        bot_values.append((x - x_bar)*(x - x_bar))

    return sum(top_values)/sum(bot_values)

def correlationCoeff(points):
    xs = util.getCol(points, 0)
    ys = util.getCol(points, 1)
    x_bar = numpy.mean(xs)
    y_bar = numpy.mean(ys)

    x_delta = []
    y_delta = []
    x_bot_delta = []
    y_bot_delta = []
    for point in points:
        x = point[0]
        y = point[1]

        topX = (x - x_bar)
        topY = (y - y_bar)
        x_delta.append(topX)
        y_delta.append(topY)
        x_bot_delta.append(topX*topX)
        y_bot_delta.append(topY*topY)

    top = sum(x_delta)*sum(y_delta)
    bot = math.sqrt(sum(x_bot_delta)*sum(y_bot_delta))
    return top/bot

def covariance(points):
    xs = util.getCol(points, 0)
    ys = util.getCol(points, 1)
    x_bar = numpy.mean(xs)
    y_bar = numpy.mean(ys)

    def topPart(point):
        return math.pow((point[0] - x_bar),2) * math.pow((point[1] - y_bar),2)

    top = [ topPart(point) for point in points ]
    return sum(top)/(len(points)-1)

def linear_regression(points):
    xs = util.getCol(points, 0)
    ys = util.getCol(points, 1)
    x_bar = numpy.mean(xs)
    y_bar = numpy.mean(ys)

    m = slope(points, x_bar, y_bar)
    b = y_bar - m*x_bar

    def line(x):
        return m*x + b
    return line

def graphablePoints(points):
    xs = util.getCol(points, 0)
    max_x = max(xs)
    min_x = min(xs)
    getY = linear_regression(points)

    return [[min_x, getY(min_x)], [max_x, getY(max_x)]]

def prod(iterable):
    """ basically sum() but for products """
    return reduce(operator.mul, iterable, 1)

def gaussian(x, mean, sdev):
    """ Computes a gaussian """
    first, second = 0, 0
    if sdev > 0:
        first = 1 / (math.sqrt(2 * math.pi) * sdev)
        second = math.e ** (-((x - mean) ** 2) / (2 * (sdev ** 2)))
    return first * second

def get_gaussian_application(col):
    """ Returns a function that applys the gaussian to X
    without recalculating the mean and sdev each time

    :param col Assumes instances of attribute for some label
    """

    mean = numpy.mean(col)
    sdev = numpy.std(col)
    return partial(gaussian, mean=mean, sdev=sdev)

def gaussian_probability(x, col):
    """ Gets the Gaussian probability
    WARNING: this is really inefficient in a loop becuase it will
    recalculate the mean and sdev each time. Just a heads up.
    """
    return get_gaussian_application(col)(x)


if __name__ == '__main__':
    table = [[6, 5, 183.0, 77.0, 3530, 20.1, 79, 2, 'mercedes benz 300d', 21497],
    [5, 8, 350.0, 125.0, 3900, 17.4, 79, 1, 'cadillac eldorado', 14668],
    [7, 4, 141.0, 71.0, 3190, 24.8, 79, 2, 'peugeot 504', 8040],
    [5, 8, 260.0, 90.0, 3420, 22.2, 79, 1, 'oldsmobile cutlass salon brougham', 5442],
    [8, 4, 105.0, 70.0, 2200, 13.2, 79, 1, 'plymouth horizon', 4469],
    [8, 4, 105.0, 70.0, 2150, 14.9, 79, 1, 'plymouth horizon tc3', 4864],
    [9, 4, 91.0, 69.0, 2130, 14.7, 79, 2, 'fiat strada custom', 4496],
    [7, 4, 151.0, 90.0, 2670, 16.0, 79, 1, 'buick skylark limited', 4462],
    [6, 6, 173.0, 115.0, 2700, 12.9, 79, 1, 'oldsmobile omega brougham', 4582],
    [8, 4, 151.0, 90.0, 2556, 13.2, 79, 1, 'pontiac phoenix', 4089]]

    import table_utils
    # filteredTable = table_utils.getWhere(table, [(1, 4)])
    # getGaussianProbability = get_gaussian_application(table_utils.getCol(filteredTable, 4))
    # print(getGaussianProbability(2200))
    #
    print(gaussian(2400 ,2482, 377))


### table_utils.py
def _validRow(row, where):
    """ Returns True if row matches where

    - where is a 2d array of index, value tuples
        ex: [(0, 'cats'), (1, 230)]
    """
    for index, value in where:
        if row[index] != value:
            return False

    return True

def getWhere(table, where):
    """ Gets rows that match the points defined in "where"
    ex: getWhere(table, [(1, 'dogs'), (0, 20)]))

    - where is a 2d array of index, value tuples
        ex: [(0, 'cats'), (1, 230)]
        note: These are AND'd together.
    """

    newTable = []
    for row in table:
        if _validRow(row, where):
            newTable.append(row)
    return newTable

def getCol(table, index):
    """ Gets a col by an index
    Ignores "NA"
    """
    col = []
    for row in table:
        if (row[index] == 'NA'): continue
        col.append(row[index])
    return col

def mapCol(table, colIndex, function):
    """ Applys the function to every item in the column """
    for row in table:
        row[colIndex] = function(row[colIndex])
    return table

if __name__ == "__main__":
    table = [
    [25, 'cats', 300],
    [50, 'dogs', 3000],
    [75, 'chinchillas', 4000],
    [20, 'horses', 3200],
    [20, 'lizards', 1000],
    [20, 'bloops', 1500],
    [35, 'dogs', 5000],
    [20, 'dogs', 6000]
    ]

    where = [(1, 'dogs'), (0, 20)]
    print("GetWhere", getWhere(table, where))
    print("MapCol", mapCol(table, 2, lambda x: x**2))


### Naive Bayes

import table_utils
import math_utils as math

def _applyGaussian(table, indices):
    for index in indices:
        col = table_utils.getCol(table, index)
        applyGaussian = math.get_gaussian_application(col)
        table = table_utils.mapCol(table, index, applyGaussian)
    return table

def _probabilityOfXGivenH(table, x, h):
    """ Calculates P(X|H)
    - x is a tuple of (index, value)
    - h is a tuple of (index, value)
    """

    # Get table given H
    tableOfH = table_utils.getWhere(table, [h])

    # Get all the X instances where H
    tableOfXGivenH = table_utils.getWhere(tableOfH, [x])

    return (1.0 * len(tableOfXGivenH))/ (1.0 * len(tableOfH))

def _totalCases(table, label):
    """ Returns the total number of cases
    in the table where table[attrIndex]
    equals 'test'

    - label is a tuple of (index, value)
    """

    filteredTable = table_utils.getWhere(table, [label])
    return len(filteredTable)

def _priorProbability(table, label):
    """ Calculates P(X)
    where X is attribute at table[attrIndex] that
    equals 'test'

    - label is a tuple of (index, value)
    """

    total = len(table)
    count = _totalCases(table, label)
    return count*1.0/total*1.0

def probability(table, instance, label, contIndices = []):
    """ Calculates P(H|X) or Bayes Theorem
    - instance is an array of tuples [(index, value), (index2, value2), ...]
    - label is a tuple (index, value)
    """
    prior = _priorProbability(table, label)
    probabilities = [prior]

    for attribute in instance:
        index, value = attribute

        # Calculate probablity based on cont or cat
        prob = None
        if index in contIndices:
            temp_table = table_utils.getWhere(table, [label])
            col = table_utils.getCol(temp_table, index)
            prob = math.gaussian_probability(value, col)
        else:
            prob = _probabilityOfXGivenH(table, attribute, label)

        probabilities.append(prob)

    return math.prod(probabilities)

def predict_label(training, instance, label_index, contIndices=[]):
    """ Predicts a label for the instance based on the training set
    - instance is an array of tuples [(index, value), (index2, value2), ...]
    - labelIndex is the column where the label is

    Returns the label and it's probability
    """
    all_labels = set(table_utils.getCol(training, label_index))
    most_likely_label = None
    most_likely_probability = None
    for label_value in all_labels:
        label = (label_index, label_value)
        prob = probability(training, instance, label, contIndices)

        # If this label is more likely, let's return it
        if most_likely_probability == None or prob > most_likely_probability:
            most_likely_probability = prob
            most_likely_label = label_value

    return most_likely_label, most_likely_probability


### constants

#Department of energy ratings
DOE_RATINGS = {
    10: 45,
    9: 37,
    8: 31,
    7: 27,
    6: 24,
    5: 20,
    4: 17,
    3: 15,
    2: 14,
    1: 0
}

ORIGINS = {
    1 : "USA",
    2 : "Europe",
    3 : "Japan"
}

INDICES = {
    'mpg'          : 0,  # auto-data dataset
    'cylinders'    : 1,
    'displacement' : 2,
    'horsepower'   : 3,
    'weight'       : 4,
    'acceleration' : 5,
    'year'         : 6,
    'origin'       : 7,
    'name'         : 8,
    'msrp'         : 9,

    'class'        : 0,  # titanic dataset
    'age'          : 1,
    'sex'          : 2,
    'survived'     : 3
}

NHTSA = {
    5 : 3500,
    4 : 3000,
    3 : 2500,
    2 : 2000,
    1 : 0
}


### Classifier_util

import util
import numpy
import table_utils

def _split(labels):
    """ Divides up the labels by their actual label
    returns a dictionary of labels
    """
    groups = {}

    for label in labels:
        actual, predicted = label

        try:
            groups[actual].append((actual, predicted))
        except KeyError:
            groups[actual] = [(actual, predicted)]

    return groups

def accuracy(labels):
    """
    Returns multiclass accuracy

    :param labels: list of tuples with [(actual, predicted), ...]
    :return: accuracy
    """
    correct = 0
    all_labels = list(set([labels[i][0] for i in range(len(labels))]))  # set of all the possible labels
    accuracies = [0] * len(all_labels)  # accuracies of each label

    for i in range(len(accuracies)):
        current_label = all_labels[i]
        for label in labels:
            actual, predicted = label
            if actual == current_label and predicted == current_label:
                accuracies[i] += 1  # true positives
            elif actual != current_label and predicted != current_label:
                accuracies[i] += 1  # true negatives

    length = len(labels)
    # Does the mean of all the (TP + TN) / (All labels)
    return numpy.mean([float(an_accuracy) / float(length) for an_accuracy in accuracies])


def _findFalses(splitLabels, forLabel):
    """ Takes an array of labels, counts the number of FP and FN """

    falses = 0
    for row in splitLabels:
        for actual, predicted in row:

            # If either the predicted or actual is the label we care about
            if actual == forLabel:
                if actual != predicted: #if label is false
                    falses += 1
            elif predicted == forLabel:
                if actual != predicted:
                    falses += 1
    return falses


if __name__ == '__main__':
    labels = [(1, 1), (1, 4), (1, 2), (2, 2), (2, 3), (3, 3)]
    print _split(labels)
